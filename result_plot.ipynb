{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import config as conf\n",
    "\n",
    "from data.mnist import Mnist\n",
    "from models.vae import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading MNIST Dataset and Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Hanlin/Documents/Python Scripts/VAE-MNIST-tensorflow2-master/learned-models/VAE-MNIST-tf2\\\\VAE-MNIST\\\\VAE-MNIST-results.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15100/3876918370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_rslt_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_rslt_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_rslt_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mencoder_loss_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_loss_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Hanlin/Documents/Python Scripts/VAE-MNIST-tensorflow2-master/learned-models/VAE-MNIST-tf2\\\\VAE-MNIST\\\\VAE-MNIST-results.pickle'"
     ]
    }
   ],
   "source": [
    "loader = Mnist()\n",
    "\n",
    "model_rslt_name = \"%s-results.pickle\" % conf.MODEL_NAME\n",
    "\n",
    "model_save_path = os.path.join(conf.MODEL_SAVE_DIR, conf.MODEL_NAME)\n",
    "model_rslt_path = os.path.join(model_save_path, model_rslt_name)\n",
    "\n",
    "with open(model_rslt_path, \"rb\") as f:\n",
    "    encoder_loss_mean, decoder_loss_mean, loss_mean, gs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ploting the Encoder and Decoder Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(1, len(encoder_loss_mean)+1)\n",
    "plt.figure(figsize=[20, 5], facecolor=\"white\")\n",
    "plt.plot(t, encoder_loss_mean, label=\"Encoder Loss per Epoch\")\n",
    "plt.plot(t, decoder_loss_mean, label=\"Decoder Loss per Epoch\")\n",
    "plt.plot(t, loss_mean, label=\"Loss per Epoch\")\n",
    "plt.xlim(1, 100)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Image Generation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list = [1, 10, 20, 50, 100]\n",
    "view_range = 15 # Should be less than conf.BATCH_SIZE\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1+len(view_list), figsize=[view_range, 10], facecolor=\"white\")\n",
    "axs[0].imshow(np.hstack(np.reshape(loader.train_features[:view_range], newshape=[view_range]+loader.feature_shape)), cmap=\"gray\")\n",
    "axs[0].set_title(\"Ground Truth\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "for i, idx in enumerate(view_list, 1):\n",
    "    g = gs[idx-1]\n",
    "    axs[i].imshow(np.hstack(np.reshape(g[:view_range], newshape=[view_range]+loader.feature_shape)), cmap=\"gray\")\n",
    "    axs[i].set_title(\"Epoch: %i\" % idx)\n",
    "    axs[i].axis(\"off\")\n",
    "    \n",
    "plt.savefig(os.path.join(model_save_path, \"image_generation_results.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Loading Ckeckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(conf.MODEL_SAVE_DIR, conf.MODEL_NAME)\n",
    "model_ckpt_path = os.path.join(model_save_path, \"model-ckpt\")\n",
    "\n",
    "latent_depth = conf.LATENT_DEPTH\n",
    "feature_depth = loader.feature_depth\n",
    "\n",
    "model = VAE(latent_depth, feature_depth)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(encoder=model.encoder, decoder=model.decoder)\n",
    "\n",
    "ckpt.restore(tf.train.latest_checkpoint(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Random Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.random.normal(size=[150, latent_depth]).astype(np.float32)\n",
    "f = model.decode(eps, training=False)\n",
    "\n",
    "plt.figure(figsize=[15, 10], facecolor=\"white\")\n",
    "plt.imshow(np.hstack(np.hstack(np.reshape(f, newshape=[10, 15]+loader.feature_shape))), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Randomly Generated Images\")\n",
    "\n",
    "plt.savefig(os.path.join(model_save_path, \"randomly_generated_images.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plotting the Latent Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 32\n",
    "view_list = [1, 10, 20, 50, 100]\n",
    "\n",
    "eps = np.random.normal(size=[num_points, latent_depth]).astype(np.float32)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(view_list), figsize=[10, 5*len(view_list)], facecolor=\"white\")\n",
    "for i, idx in enumerate(view_list):\n",
    "    model_ckpt_path = os.path.join(model_save_path, \"model-ckpt-%i\" % idx)\n",
    "    ckpt.restore(model_ckpt_path)\n",
    "\n",
    "    mu, log_sigma = model.encode(loader.train_features[:num_points], training=False)\n",
    "    z = np.random.normal(size=[num_points, latent_depth]).astype(np.float32)\n",
    "    z = model.reparam(z, mu, log_sigma)\n",
    "\n",
    "    axs[i].scatter(eps[:, 0], eps[:, 1], label=\"Normal Distribution\")\n",
    "    axs[i].scatter(z[:, 0], z[:, 1], label=\"Latent Distribution\")\n",
    "    \n",
    "    axs[i].grid()\n",
    "    axs[i].legend()\n",
    "    axs[i].set_title(\"Epoch: %i\" % idx)\n",
    "    axs[i].set_xlim(-10, 10)\n",
    "    axs[i].set_ylim(-5, 5)\n",
    "    \n",
    "plt.savefig(os.path.join(model_save_path, \"latent_distribution_results.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
